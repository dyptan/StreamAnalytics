---
# ***************************
# *** SPARK tests section ***
# ***************************

  - name: Clone tests
    shell: git clone -b master --depth 1 --single-branch https://6936784d69eb813cbcdf18ed2554e174f6f974ce@github.com/mapr/private-qa.git
    become: true
    become_user: mapr

  - block:
      - name: Set Spark executor memory
        lineinfile:
          dest={{ spark_home_dir.stdout }}/conf/spark-defaults.conf
          line="spark.executor.memory        5g"
          insertafter=EOF
      - name: Set Spark executor cores
        lineinfile:
          dest={{ spark_home_dir.stdout }}/conf/spark-defaults.conf
          line="spark.executor.cores     5"
          insertafter=EOF
      - name: Set Spark executor instances
        lineinfile:
          dest={{ spark_home_dir.stdout }}/conf/spark-defaults.conf
          line="spark.executor.instances      3"
          insertafter=EOF
      - name: Set Spark driver cores
        lineinfile:
          dest={{ spark_home_dir.stdout }}/conf/spark-defaults.conf
          line="spark.driver.cores      2"
          insertafter=EOF
      - name: Set Spark driver memory
        lineinfile:
          dest={{ spark_home_dir.stdout }}/conf/spark-defaults.conf
          line="spark.driver.memory      2g"
          insertafter=EOF


  - name: Configure Hive
    include: configure_hive.yml
    when: (hostname in packages_eco.hive.host)

  - name: Install Kazoo
    shell: pip install kazoo
    sudo: yes

  - name: Upgrade pip
    shell: pip install --upgrade pip
    sudo: yes

  - name: Install Numpy
    shell: pip install numpy
    sudo: yes

  - name: Install Pandas
    shell: pip install pandas
    sudo: yes

  - name: Install PyArrow
    shell: pip install pyarrow==0.11.0
    sudo: yes

  - name: Install Pyjavaproperties
    shell: pip install pyjavaproperties
    sudo: yes

  - name: Install Wheel
    shell: pip install wheel
    sudo: yes

  - name: Install Pyspark-Sql
    shell: pip install pyspark[sql]
    sudo: yes

# ****************************
# *** Apache Kafka section ***
# ****************************

  - name: Set Apache Kafka home
    shell: echo /home/mapr/apache_kafka
    register: apache_kafka_home

  - name: Download Apache Kafka
    get_url:
      url: https://archive.apache.org/dist/kafka/1.1.1/kafka_2.11-1.1.1.tgz
      dest: '{{ apache_kafka_home.stdout }}.tgz'
      timeout: 30
    when: mapr_version < 620

  - name: Download Apache Kafka
    get_url:
      url: https://archive.apache.org/dist/kafka/2.1.1/kafka_2.12-2.1.1.tgz
      dest: '{{ apache_kafka_home.stdout }}.tgz'
      timeout: 30
    when: mapr_version >= 620

  - name: Unzip Apache Kafka
    shell: mkdir {{ apache_kafka_home.stdout }} && tar -xzf {{ apache_kafka_home.stdout }}.tgz -C {{ apache_kafka_home.stdout }} --strip-components 1
    become: true
    become_user: mapr
    when: (hostname == packages_eco.kafka.host|first_host)
    ignore_errors: true

  - name: Change Kafka Zookeeper properties
    lineinfile:
      dest={{ apache_kafka_home.stdout }}/config/server.properties
      line="delete.topic.enable=true"
      insertafter=EOF
    ignore_errors: true

  - name: Change Apache Kafka port
    lineinfile:
      dest={{ apache_kafka_home.stdout }}/config/server.properties
      line="listeners=PLAINTEXT://:9093"
      insertafter=EOF
    when: mapr_version >= 620
    ignore_errors: true

  - name: Change Kafka Retention Check Period
    lineinfile:
      dest={{ apache_kafka_home.stdout }}/config/server.properties
      regexp="^log.retention.check.interval.ms="
      line="log.retention.check.interval.ms=1000"
    ignore_errors: true

  - name: Start Apache Zookeeper
    shell: '{{ apache_kafka_home.stdout }}/bin/zookeeper-server-start.sh -daemon {{ apache_kafka_home.stdout }}/config/zookeeper.properties'
    become: true
    become_user: mapr
    when: (hostname == packages_eco.kafka.host|first_host)
    ignore_errors: true

  - name: Start Kafka server
    shell: '{{ apache_kafka_home.stdout }}/bin/kafka-server-start.sh -daemon {{ apache_kafka_home.stdout }}/config/server.properties'
    become: true
    become_user: mapr
    when: (hostname == packages_eco.kafka.host|first_host)
    ignore_errors: true

# ****************************
# *** MapR Gateway section ***
# ****************************

  - name: Update gateway config
    lineinfile:
      dest=/opt/mapr/conf/gateway.conf
      line='gateway.es.logcompaction.statsupdate.interval.ms=1000'
      insertafter=EOF
    when: hostname in packages_core.gateway.host
    ignore_errors: true

  - name: Restart gateway service
    shell: 'maprcli node services -nodes {{ hostname }} -name gateway -action restart'
    become: true
    become_user: mapr
    when: hostname in packages_core.gateway.host
    ignore_errors: true

  - name: Download Mongo Java Driver
    get_url:
      url: https://repo1.maven.org/maven2/org/mongodb/mongo-java-driver/3.12.0/mongo-java-driver-3.12.0.jar
      dest: '{{ spark_home_dir.stdout }}/jars/mongo-java-driver-3.12.0.jar'
      timeout: 30
    become: true
    become_user: mapr


  - name: Download Mongo Hadoop Conector
    get_url:
      url: https://repo1.maven.org/maven2/org/mongodb/mongo-hadoop/mongo-hadoop-core/2.0.2/mongo-hadoop-core-2.0.2.jar
      dest: '{{ spark_home_dir.stdout }}/jars/mongo-hadoop-core-2.0.2.jar'
      timeout: 30
    become: true
    become_user: mapr

  - name: Download Mongo Hadoop Conector
    get_url:
      url: https://repo1.maven.org/maven2/org/mongodb/spark/mongo-spark-connector_2.11/2.4.0/mongo-spark-connector_2.11-2.4.0.jar
      dest: '{{ spark_home_dir.stdout }}/jars/mongo-spark-connector_2.11-2.4.0.jar'
      timeout: 30
    become: true
    become_user: mapr

  - name: Copy hive-site.xml
    template: src=thrift/hive-site.xml.{{security}} dest={{ spark_home_dir.stdout }}/conf/hive-site.xml
    become: yes
    become_user: mapr
    when:
      - mapr_version >= 631
      - packages_eco.hive.host
      - packages_eco.spark.use_for_hive
      - hostname in packages_eco.spark_thriftserver.host

  - name: Start thrift server
    shell: /opt/mapr/spark/spark-*/sbin/stop-thriftserver.sh; /opt/mapr/spark/spark-*/sbin/start-thriftserver.sh --hiveconf hive.server2.thrift.port=2304
    become_user: mapr
    when:
      - mapr_version >= 631
      - hostname in packages_eco.spark_thriftserver.host

