---
  - name: Wait for CLDB start
    shell: hadoop fs -ls /
    become: true
    become_user: mapr
    register: command_result
    retries: 10
    delay: 10
    until: command_result | success

  - name: spark on hive configure
    shell: ln -s /opt/mapr/hive/hive-*/conf/hive-site.xml /opt/mapr/spark/spark-*/conf
    become: yes
    become_user: mapr
    ignore_errors: yes
    when:
        - packages_eco.hive.host
        - packages_eco.spark.use_for_hive

  - name: spark16 on hive12 configure
    include: spark16-onHive12-configure.yml
    when:
        - packages_eco.hive.host
        - packages_eco.spark.use_for_hive
        - spark_version.stdout | version_compare('1.6.1', '==')

  - name: spark210 on mesos130 configure
    include: spark-onMesos-configure.yml
    when:
        - spark_version.stdout | version_compare('2.1.0', '>=')
        - packages_eco.spark.use_for_mesos

  - name: Install Python-pip [RedHat]
    yum: name=python-pip disable_gpg_check=yes
    sudo: yes
    when: (ansible_os_family == 'RedHat')

  - name: Install Python-pip [Debian]
    apt: name=python-pip
    sudo: yes
    when: (ansible_os_family == 'Debian')

  - name: Install Python-pip [Suse]
    zypper: name=python-pip
    sudo: yes
    when: (ansible_os_family == 'Suse')

  - name: Configure spark jceks
    include: configure_spark_jceks.yml
    when: (mapr_eco_version == 'MEP505') and (security == "maprsasl")

